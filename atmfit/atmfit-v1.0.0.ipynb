{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1UzD4JTTfT0zpwREfByMLgebAKUaQqXdi",
      "authorship_tag": "ABX9TyOwhA4ODWLIJKB8vlkrs6vf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/interstellxr/deshima-atmfit/blob/main/atmfit/atmfit-v1.0.0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8BTtHOikDAqB",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de832876-68f0-4a80-d074-0114647fd219"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking for updates into /root/.casa/data\n",
            "measures_update ... acquiring the lock ... \n",
            "A measures update has been requested by the force argument\n",
            "  ... connecting to ftp.astron.nl ...\n",
            "  ... downloading WSRT_Measures_20240718-160002.ztar from ASTRON server to /root/.casa/data ...\n",
            "  ... measures data updated at /root/.casa/data\n",
            "Requirement already satisfied: xarray in /usr/local/lib/python3.10/dist-packages (2023.7.0)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.10/dist-packages (from xarray) (1.25.2)\n",
            "Requirement already satisfied: pandas>=1.4 in /usr/local/lib/python3.10/dist-packages (from xarray) (2.0.3)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from xarray) (24.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4->xarray) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4->xarray) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4->xarray) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.4->xarray) (1.16.0)\n",
            "Requirement already satisfied: xarray[accel] in /usr/local/lib/python3.10/dist-packages (2023.7.0)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.10/dist-packages (from xarray[accel]) (1.25.2)\n",
            "Requirement already satisfied: pandas>=1.4 in /usr/local/lib/python3.10/dist-packages (from xarray[accel]) (2.0.3)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from xarray[accel]) (24.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xarray[accel]) (1.11.4)\n",
            "Requirement already satisfied: bottleneck in /usr/local/lib/python3.10/dist-packages (from xarray[accel]) (1.4.0)\n",
            "Requirement already satisfied: numbagg in /usr/local/lib/python3.10/dist-packages (from xarray[accel]) (0.8.1)\n",
            "Requirement already satisfied: flox in /usr/local/lib/python3.10/dist-packages (from xarray[accel]) (0.9.8)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4->xarray[accel]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4->xarray[accel]) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4->xarray[accel]) (2024.1)\n",
            "Requirement already satisfied: numpy-groupies>=0.9.19 in /usr/local/lib/python3.10/dist-packages (from flox->xarray[accel]) (0.11.1)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from flox->xarray[accel]) (0.12.1)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from numbagg->xarray[accel]) (0.58.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.4->xarray[accel]) (1.16.0)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->numbagg->xarray[accel]) (0.41.1)\n",
            "Requirement already satisfied: astropy in /usr/local/lib/python3.10/dist-packages (5.3.4)\n",
            "Requirement already satisfied: numpy<2,>=1.21 in /usr/local/lib/python3.10/dist-packages (from astropy) (1.25.2)\n",
            "Requirement already satisfied: pyerfa>=2.0 in /usr/local/lib/python3.10/dist-packages (from astropy) (2.0.1.4)\n",
            "Requirement already satisfied: PyYAML>=3.13 in /usr/local/lib/python3.10/dist-packages (from astropy) (6.0.1)\n",
            "Requirement already satisfied: packaging>=19.0 in /usr/local/lib/python3.10/dist-packages (from astropy) (24.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Some or all of the expected auto updates did not happen.\n",
            "This indicates that measurespath is not empty and does not contain data maintained by casaconfig.\n",
            "If the IERSeop2000 table is found in datapth then casatools will import.\n",
            "\n",
            "The contents of measurespath do not appear to be casarundata. CASA may still work if the data can be found in datapath.\n",
            "visit https://casadocs.readthedocs.io/en/stable/notebooks/external-data.html for more information\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# @title Import libraries & dependencies\n",
        "\n",
        "! pip install -q casatools jupyter-io\n",
        "! python3 -m casaconfig --measures-update --force\n",
        "! pip install xarray\n",
        "! pip install \"xarray[accel]\"\n",
        "! pip install -q decode zarr\n",
        "! pip install astropy\n",
        "\n",
        "# standard library\n",
        "from typing import Any, Tuple\n",
        "\n",
        "# dependencies\n",
        "import casatools\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# for xarray\n",
        "import pandas as pd\n",
        "import decode as dc\n",
        "import xarray as xr\n",
        "\n",
        "# for the fitting function\n",
        "from scipy.optimize import least_squares\n",
        "from scipy.interpolate import interp1d\n",
        "from astropy.io import fits"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ATM model (Pardo et al. 2001)\n",
        "\n",
        "def get_tau(\n",
        "    f_min: float,\n",
        "    f_max: float,\n",
        "    f_step: float,\n",
        "    pwv: float,\n",
        "    **atm_params: Any,\n",
        ") -> Tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\"Compute of zenith opacities at given frequencies.\n",
        "\n",
        "    Args:\n",
        "        f_min: Minimum frequency (in units of Hz).\n",
        "        f_max: Maximum frequency (in units of Hz).\n",
        "        f_step: Frequency step (in units of Hz).\n",
        "        pwv: Precipitable water vapor (in units of mm).\n",
        "        atm_params: Parameters fo the ATM model.\n",
        "\n",
        "    Returns:\n",
        "        freq: Array of frequencies (in units of Hz).\n",
        "        tau: Array of zenith opacities at the frequencies.\n",
        "\n",
        "    \"\"\"\n",
        "    at = casatools.atmosphere()\n",
        "    qa = casatools.quanta()\n",
        "\n",
        "    f_cent = qa.quantity((f_min + f_max) / 2, \"Hz\")\n",
        "    f_width = qa.quantity(f_max - f_min + f_step, \"Hz\")\n",
        "    f_step = qa.quantity(f_step, \"Hz\")\n",
        "    pwv = qa.quantity(pwv, \"mm\")\n",
        "\n",
        "    at.initAtmProfile(**atm_params)\n",
        "    at.initSpectralWindow(1, f_cent, f_width, f_step)\n",
        "    at.setUserWH2O(pwv)\n",
        "\n",
        "    freq = qa.convert(at.getSpectralWindow(), \"Hz\")[\"value\"]\n",
        "    tau = at.getDryOpacitySpec()[1] + at.getWetOpacitySpec()[1]['value']\n",
        "\n",
        "    return freq, tau"
      ],
      "metadata": {
        "id": "QOMJ7wojDVnu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Main function (ATM_fit)\n",
        "\n",
        "def ATM_fit(da,ddb, pwv0, dt, *ranges_weights): # Obligatory input : DEMS (xarray.DataArray)\n",
        "# Optional inputs : initial PWV value (float), time step (int), weighted frequency ranges (tuples of floats : (fmin, fmax, weight))\n",
        "\n",
        "\n",
        "    ## ERROR HANDLING ##\n",
        "\n",
        "    ranges = []\n",
        "    weights = []\n",
        "\n",
        "    if ranges_weights is None:\n",
        "        ranges_weights = (min(da.frequency.values), max(da.frequency.values), 1)\n",
        "\n",
        "    for r_w in ranges_weights:\n",
        "        if len(r_w) != 3:\n",
        "            raise ValueError(\"Each range must contain minimum and maximum frequencies and have a corresponding weight.\")\n",
        "        ranges.append(r_w[0:2])\n",
        "        weights.append(r_w[-1])\n",
        "\n",
        "    if not isinstance(da, xr.DataArray):\n",
        "        raise TypeError(f\"Argument '{da}' must be an xarray DataArray, got {type(da).__name__} instead.\")\n",
        "\n",
        "    if not isinstance(ddb, fits.HDUList):\n",
        "        raise TypeError(f\"Argument '{ddb}' must be a .fits, got {type(ddb).__name__} instead.\")\n",
        "\n",
        "    for k,frange in enumerate(ranges):\n",
        "        w = weights[k]\n",
        "        for arg in [frange[0], frange[1], pwv0, w]:\n",
        "            if arg is not None and not isinstance(arg, (int, float)):\n",
        "                raise TypeError(f\"Argument '{arg}' must be a number, got {type(arg).__name__} instead.\")\n",
        "            if arg is not None and arg is not pwv0 and arg is not w and arg <= 0:\n",
        "                raise ValueError(f\"Argument '{arg}' must be a strictly positive number.\")\n",
        "            if (arg is pwv0 or arg is w) and arg is not None and arg < 0:\n",
        "                raise ValueError(f\"Argument '{arg}' must be a positive number or null.\")\n",
        "\n",
        "        if k != 0 and k!= len(ranges)-1:\n",
        "            if frange[0] is None or frange[1] is None:\n",
        "                raise ValueError(f\"Both fmin and fmax must be specified.\")\n",
        "\n",
        "        if frange[0] is not None and frange[1] is not None:\n",
        "            if frange[0] > frange[1]:\n",
        "                raise ValueError(f\"fmin must be less than or equal to fmax.\")\n",
        "\n",
        "    if dt is not None and dt >= len(da.time.values):\n",
        "        print(\"WARNING: step is greater than time series length, which might not be intended.\")\n",
        "\n",
        "    if dt is not None and ( not isinstance(dt, int) or dt<=0 ) :\n",
        "        raise TypeError(f\"dt must be a positive integer, got {type(dt).__name__} instead.\")\n",
        "\n",
        "\n",
        "    ## CREATE ATM PARAMETERS ##\n",
        "\n",
        "    # The atm model needs certain parameters as inputs. We fetch these from the DEMS array if they are available.\n",
        "    # If they are available, we get the first non nan value from the corresponding coordinate (since the parameters are assumed constant).\n",
        "    # We must be careful of units : 2023 data sets have different units for pressure and temperature than 2024 data sets. Check this!\n",
        "\n",
        "    def get_first_non_nan(arr, default):\n",
        "        for value in arr:\n",
        "            if not np.isnan(value):\n",
        "                return value\n",
        "        return default\n",
        "\n",
        "    default_pressure = 570  # mbar\n",
        "    default_humidity = 20  # percent\n",
        "    default_temperature = 270 # 0 C or 270 K (check DEMS)\n",
        "\n",
        "    pressure_value = get_first_non_nan(da.pressure.values, default_pressure) /100 # convert Pa to mbar (check DEMS to see if needed)\n",
        "    humidity_value = get_first_non_nan(da.humidity.values, default_humidity) * 100 # humidity in fraction or percent form? (check DEMS)\n",
        "    temperature_value = get_first_non_nan(da.temperature.values, default_temperature) #+ 273.15 # convert to Kelvin (check DEMS to see if needed)\n",
        "\n",
        "    atm_params = {\n",
        "        'atmType': 1,\n",
        "        'humidity': humidity_value,\n",
        "        'temperature': f'{temperature_value} K',\n",
        "        'altitude': '4860 m',\n",
        "        'pressure': f'{pressure_value} mbar',\n",
        "        'h0': '2.0 km',\n",
        "    }\n",
        "\n",
        "\n",
        "    ## LOAD DATA ##\n",
        "\n",
        "    T_atmos = temperature_value\n",
        "\n",
        "    freq = da.frequency.values\n",
        "    freq_unsorted = freq\n",
        "    sorted_indices_before_intersect = np.argsort(freq_unsorted)\n",
        "\n",
        "    kidfilt = ddb[\"KIDFILT\"] # fits file\n",
        "    masterid = kidfilt.data[\"masterid\"] # channel IDs of filter response functions (more than in DEMS)\n",
        "    nu = kidfilt.data[\"Raw Toptica F\"] # corresponding frequencies (same for all IDs normally)\n",
        "    R = kidfilt.data[\"Raw df resp.\"] # corresponding responses (y data)\n",
        "\n",
        "    common_values = np.intersect1d(masterid, da.chan.values) # find common channels between DEMS and DDB\n",
        "    indices_array1 = np.where(np.isin(masterid, common_values))[0] # DDB common indices\n",
        "    indices_array2 = np.where(np.isin(da.chan.values, common_values))[0] # DEMS common indices\n",
        "    missing_indices = np.where(~np.isin(da.chan.values, common_values))[0] # missing indices (DEMS)\n",
        "\n",
        "    # check dems ids are subset of master ids\n",
        "    if not (set(da.chan.data) <= set(kidfilt.data[\"masterid\"])):\n",
        "        print(f\"WARNING: DEMS channels with IDs {da.chan.values[missing_indices]} not found in DDB file.\")\n",
        "\n",
        "    nu = nu[indices_array1]\n",
        "    R = R[indices_array1]\n",
        "    freq = freq[indices_array2]\n",
        "\n",
        "    sorted_indices = np.argsort(freq) # sort frequencies (just for simplicity in the following lines)\n",
        "    freq = freq[sorted_indices]\n",
        "\n",
        "    for range in ranges:\n",
        "        fmin = range[0]\n",
        "        fmax = range[1]\n",
        "        if (fmin is not None and fmin < freq[0]) :\n",
        "            raise ValueError(f\"fmin must be within the frequency range.\")\n",
        "\n",
        "        if (fmax is not None and fmax > freq[-1]) :\n",
        "            raise ValueError(f\"fmax must be within the frequency range.\")\n",
        "\n",
        "    N = len(freq)-1\n",
        "    m = freq[0]\n",
        "    M = freq[-1]\n",
        "    step = (freq[-1] - freq[0])/N # we want a step as close to the data as possible\n",
        "\n",
        "    # set default values to arguments\n",
        "    if pwv0 is None:\n",
        "        init_PWV = 1.0\n",
        "    else :\n",
        "        init_PWV = pwv0\n",
        "    if dt is None:\n",
        "        time_step = 1\n",
        "    else :\n",
        "        time_step = dt\n",
        "\n",
        "\n",
        "    ## FITTING FUNCTION ##\n",
        "\n",
        "    def Tb_fit(t,freq,fit_T_atm=True, T_atm=None,nu=None, R=None): # take in boolean to see if we should fit for T_atm (only for t==0)\n",
        "\n",
        "\n",
        "        ## LOAD DATA AND HANDLE NANS ##\n",
        "\n",
        "        Tb = da[t,:].values\n",
        "\n",
        "        # create an empty array with the same shape as Tb : useful for ouput (we want to keep NaNs to match input)\n",
        "        empty_Tb = np.empty_like(Tb, dtype = 'float')\n",
        "        empty_Tb[np.isnan(Tb)] = np.nan\n",
        "        empty_Tb[missing_indices] = np.nan # for DEMS channels not in the DDB, set to nans\n",
        "        empty_Tb = empty_Tb[sorted_indices_before_intersect] # sort indices\n",
        "\n",
        "        Tb = Tb[indices_array2]\n",
        "        Tb = Tb[sorted_indices]\n",
        "        valid_indices = np.where(~np.isnan(Tb)) # we need to remove nans for analysis\n",
        "        Tb_valid = Tb[valid_indices]\n",
        "        freq_valid = freq[valid_indices]\n",
        "\n",
        "        if not np.isnan(da.secz.values[t]):\n",
        "            airmass = da.secz.values[t]\n",
        "\n",
        "        else : # airmass is the last non nan value of secz before t or first non nan value after t (whichever is closest to t)\n",
        "            before_t_idx = np.where(~np.isnan(da.secz_values[:t]))[0] # last non nan before t\n",
        "            if before_t_idx.size > 0:\n",
        "                last_idx = before_t_idx[-1]\n",
        "                last = da.secz_values[last_idx]\n",
        "            else:\n",
        "                last_idx = None\n",
        "                last = np.nan\n",
        "\n",
        "            after_t_idx = np.where(~np.isnan(da.secz_values[t+1:]))[0] + t + 1 # first non nan after t\n",
        "            if after_t_idx.size > 0:\n",
        "                first_idx = after_t_idx[0]\n",
        "                first = da.secz_values[first_idx]\n",
        "            else:\n",
        "                first_idx = None\n",
        "                first = np.nan\n",
        "\n",
        "            if last_idx is not None and first_idx is not None:\n",
        "                if (t - last_idx) <= (first_idx - t): # determine which is closest\n",
        "                    airmass = last\n",
        "                else:\n",
        "                    airmass = first\n",
        "            elif last_idx is not None:\n",
        "                airmass = last\n",
        "            elif first_idx is not None:\n",
        "                airmass = first_idx\n",
        "            else:\n",
        "                airmass = 1 # default if all are NaNs\n",
        "\n",
        "\n",
        "        # R is an array of response functions (themselves arrays with x values being frequencies)\n",
        "        # so we iterate over the responses and interpolate to match frequencies\n",
        "        def interpolate_responses(frequencies, responses, freq_valid):\n",
        "            return [interp1d(freq[np.where(~np.isnan(resp))[0]], resp[np.where(~np.isnan(resp))[0]], kind='linear', bounds_error=False, fill_value=\"extrapolate\")(freq_valid) for freq, resp in zip(frequencies, responses)]\n",
        "\n",
        "        filter_responses = interpolate_responses(nu, R, freq_valid)\n",
        "        filter_responses_sorted = [filter_responses[i] for i in sorted_indices]\n",
        "        filter_responses_valid = [filter_responses_sorted[i] for i in valid_indices[0]]\n",
        "\n",
        "\n",
        "        ## CONVERT OPACITY GIVEN BY MODEL TO SKY BRIGHTNESS TEMPERATURE ##\n",
        "\n",
        "        def tau_to_T(params):\n",
        "            pwv, T_atm_ = params if fit_T_atm else (params[0], T_atm)\n",
        "            temp, tau = get_tau(m*1e9, M*1e9, step*1e9, pwv, **atm_params)\n",
        "            tau = interp1d(temp[valid_indices], tau[valid_indices], kind='linear', bounds_error=False, fill_value=\"extrapolate\")(freq_valid*1e9)\n",
        "            T_model = T_atm_ * (1 - np.exp(-tau*airmass))\n",
        "\n",
        "            filtered_T_model = [np.sum(T_model * resp)/np.sum(resp) for resp in filter_responses_valid]\n",
        "\n",
        "            return filtered_T_model\n",
        "\n",
        "\n",
        "        ## RESIDUAL FUNCTION ##\n",
        "\n",
        "        def diff(params, w):\n",
        "            return abs(Tb_valid - tau_to_T(params)) * w\n",
        "\n",
        "        weights_array = np.ones_like(Tb_valid)\n",
        "\n",
        "        for r, W in zip(ranges,weights):\n",
        "            if W is None:\n",
        "                W = 1\n",
        "            if r[0] is None and r[1] is not None:\n",
        "                mask = (freq_valid >= freq_valid[0]) & (freq_valid <= r[1])\n",
        "            if r[1] is None and r[0] is not None:\n",
        "                mask = (freq_valid >= r[0]) & (freq_valid <= freq_valid[-1])\n",
        "            if r[0] is None and r[1] is None:\n",
        "                mask = (freq_valid >= freq_valid[0]) & (freq_valid <= freq_valid[-1])\n",
        "            if r[0] is not None and r[1] is not None:\n",
        "                mask = (freq_valid >= r[0]) & (freq_valid <= r[1])\n",
        "            weights_array[np.where(mask)] = W\n",
        "\n",
        "\n",
        "        ## LEAST SQUARES FIT ##\n",
        "\n",
        "        init_params = [init_PWV, T_atm] if fit_T_atm else [init_PWV]\n",
        "        bounds = ([0, 100], [np.inf, 400]) if fit_T_atm else ([0], [np.inf])\n",
        "        result = least_squares(diff,init_params,loss='huber', kwargs={'w': weights_array}, bounds = bounds)\n",
        "\n",
        "        optim_PWV, optim_T_atm = result.x if fit_T_atm else (result.x[0], T_atm)\n",
        "\n",
        "        J = result.jac\n",
        "        cov = np.linalg.inv(J.T.dot(J))\n",
        "        std = np.sqrt(np.diagonal(cov))\n",
        "        PWV_std, T_atm_std = std if fit_T_atm else (std[0], 0)\n",
        "\n",
        "        Tmodel = tau_to_T(result.x)\n",
        "\n",
        "        # Re-insert NaN positions\n",
        "        k=0\n",
        "        for i,el in enumerate(empty_Tb):\n",
        "              if not np.isnan(el):\n",
        "                  empty_Tb[i] = Tmodel[k]\n",
        "                  k+=1\n",
        "\n",
        "        unsorted_indices = np.argsort(sorted_indices_before_intersect)\n",
        "        empty_Tb = empty_Tb[unsorted_indices] # unsort indices to match input data array\n",
        "\n",
        "        return empty_Tb, optim_PWV, optim_T_atm, PWV_std, T_atm_std # return unsorted and invalid (with NaNs) Tb_model and optimized PWV and optimized T_atm with errors\n",
        "\n",
        "\n",
        "    ## LOOP OVER TIME ##\n",
        "\n",
        "    init_time = 0\n",
        "    _, _, fitted_T_atm, _, initial_T_atm_std = Tb_fit(init_time, freq, fit_T_atm=True, T_atm=T_atmos,nu=nu,R=R)\n",
        "\n",
        "\n",
        "    time_values=pd.Series(da.time.values[0:len(da.time):time_step])\n",
        "\n",
        "    Tb_model_array = []\n",
        "    optim_PWV_array = np.array([])\n",
        "    optim_T_atm_array = np.array([])\n",
        "    PWV_std_array = np.array([])\n",
        "    T_atm_std_array = np.array([])\n",
        "\n",
        "    for time_str in time_values:\n",
        "        t = np.where(da.time.values == time_str)[0][0]\n",
        "        T, PWV, T_ATM, PWV_std, _ = Tb_fit(t,freq, fit_T_atm=False,T_atm=fitted_T_atm,nu=nu,R=R)\n",
        "        Tb_model_array.append(T)\n",
        "        optim_PWV_array = np.append(optim_PWV_array,PWV)\n",
        "        optim_T_atm_array = np.append(optim_T_atm_array, T_ATM)\n",
        "        PWV_std_array = np.append(PWV_std_array, PWV_std)\n",
        "        T_atm_std_array = np.append(T_atm_std_array, initial_T_atm_std)\n",
        "\n",
        "\n",
        "    ## CREATE THE OUTPUT DATA ARRAY ##\n",
        "\n",
        "    # if you want a seperate data array (for testing)\n",
        "    new_da = xr.DataArray(\n",
        "        np.array(Tb_model_array),\n",
        "        dims=(\"time\", \"channel\"),\n",
        "        coords={\n",
        "            \"time\": time_values,\n",
        "            \"PWV\": (\"time\", optim_PWV_array),\n",
        "            \"T_atm\": (\"time\", optim_T_atm_array),\n",
        "            \"channel\": da.chan.values,\n",
        "            \"frequency\": (\"channel\",freq_unsorted),\n",
        "            \"PWV_std\": (\"time\", PWV_std_array),\n",
        "            \"T_atm_std\": (\"time\", T_atm_std_array),\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # if you want to modify data array (so keeping all attributes and coordinates with same time length)\n",
        "    #new_da = da\n",
        "    #new_da.values = np.array(Tb_model_array)\n",
        "    #new_da.assign_coords(PWV=(\"time\",optim_PWV_array))\n",
        "    #new_da.assign_coords(T_atm=(\"time\",optim_T_atm_array))\n",
        "    #new_da.assign_coords(T_atm_std=(\"time\",T_atm_std_array))\n",
        "    #new_da.assign_coords(PWV_std=(\"time\",PWV_std_array))\n",
        "\n",
        "    # for both cases\n",
        "    new_da['PWV'].attrs['long name'] = 'Precipitable Water Vapor derived from ATM model'\n",
        "    new_da['PWV'].attrs['units'] = 'mm'\n",
        "    new_da['T_atm'].attrs['long_name'] = 'Atmospheric Temperature derived from ATM model'\n",
        "    new_da['T_atm'].attrs['units'] = 'K'\n",
        "    new_da['PWV_std'].attrs['long_name'] = 'Standard deviation of PWV derived from ATM model'\n",
        "    new_da['PWV_std'].attrs['units'] = 'mm'\n",
        "    new_da['T_atm_std'].attrs['long_name'] = 'Standard deviation of T_atm derived from ATM model'\n",
        "    new_da['T_atm_std'].attrs['units'] = 'K'\n",
        "\n",
        "    return new_da"
      ],
      "metadata": {
        "id": "50luQNYRDXon"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Function test using 14/11/2023 still data\n",
        "\n",
        "#2023 still data (temperatures in C and pressures in mbar)\n",
        "! gdown \"1LFP3bHZWfaSOvh5p_vd3d-AE0hr5EAgM\"\n",
        "da = dc.qlook.load_dems(\"dems_20231113191906.zarr.zip\")\n",
        "\n",
        "# MKID responses (2023)\n",
        "! gdown \"1gE0IJzlJpN9xrCqXSOvg7AJw1GPAxYhK\"\n",
        "hdus = fits.open(\"ddb_20231123.fits.gz\")\n",
        "\n",
        "# Call function\n",
        "NewDA = ATM_fit(da, hdus, None, 100000, (None, 230, 0)) # exclude < 230 GHz range & use a step of 100 000 (> data length => get only first set)\n",
        "NewDA"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "id": "BBw4pdSzoln_",
        "outputId": "b03816af-b5d2-4466-f78d-11d07121aaec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1LFP3bHZWfaSOvh5p_vd3d-AE0hr5EAgM\n",
            "From (redirected): https://drive.google.com/uc?id=1LFP3bHZWfaSOvh5p_vd3d-AE0hr5EAgM&confirm=t&uuid=73920312-1898-4794-ae37-505c0c4ed932\n",
            "To: /content/dems_20231113191906.zarr.zip\n",
            "100% 436M/436M [00:09<00:00, 47.7MB/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'dc' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-5c90286bf34c>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#2023 still data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' gdown \"1LFP3bHZWfaSOvh5p_vd3d-AE0hr5EAgM\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqlook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_dems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dems_20231113191906.zarr.zip\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# MKID responses (2023)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'dc' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lw = 2\n",
        "fs = 20\n",
        "ps = 10\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "idx = np.argsort(da.frequency.values)\n",
        "plt.scatter(da.frequency.values,da.values[0*10000], label = r'$T_{b,\\mathrm{atm}}$', color = 'slateblue', linewidth = lw, s = ps)\n",
        "plt.plot(da.frequency.values[idx],NewDA.values[0][idx], label = r'$T^\\mathrm{DESHIMA}_{b,\\mathrm{model}}$', color = 'k', linewidth = lw, linestyle='--')#(27/255,158/255,119/255)\n",
        "plt.tick_params(which='both', labelsize=fs, direction=\"in\")\n",
        "plt.gca().xaxis.set_ticks_position('both')\n",
        "plt.gca().yaxis.set_ticks_position('both')\n",
        "legend = plt.legend(fontsize=fs, loc=2, fancybox=False, framealpha=1.0)\n",
        "plt.ylim([0, 300])\n",
        "plt.xlim([200, 400])\n",
        "plt.grid(True, linestyle = '--', linewidth = 0.5)\n",
        "plt.xlabel('Frequency [GHz]', fontsize = fs)\n",
        "plt.ylabel('Sky Brightness Temperature [K]', fontsize = fs)"
      ],
      "metadata": {
        "id": "sqIVRfgStlJ6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}